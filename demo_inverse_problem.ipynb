{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demo notebook for inverse problems\n",
    "==================================\n",
    "\n",
    "**Table of content**\n",
    "1. [Defining an inverse problem](#defining-an-inverse-problem)\n",
    "1. [Example on CelebaHQ dataset with DPS algorithm](#example-on-celebahq-dataset-with-dps-algorithm)\n",
    "1. [Example on FFHQ dataset with $\\Pi\\text{GDM}$ algorithm](#example-on-ffhq-dataset-with--algorithm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining an inverse problem\n",
    "\n",
    "Inverse problem,\n",
    "\\begin{equation*}\n",
    "    y = A x + \\sigma \\ \\epsilon\n",
    "\\end{equation*}\n",
    "- $y$ the observation\n",
    "- $A$ the degradation operator\n",
    "- $\\sigma \\ \\epsilon$ Gaussian noise $\\mathcal{N}(0, \\sigma I)$\n",
    "\n",
    "Let's see how to\n",
    "\n",
    "1. Load an image\n",
    "1. Load the degradation operator $A$\n",
    "1. Plot the observation $y$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_source.utils import load_image, display_image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load the image\n",
    "img_path = \"./material/celebahq_img/00010.jpg\"\n",
    "x_origin = load_image(img_path)\n",
    "\n",
    "# plot the image\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "display_image(x_origin, ax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the degradation operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load SR16 degradation operator\n",
    "\n",
    "It reduces the resolution of the image by $16$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "\n",
    "# load the degradation operator\n",
    "path_operator = f\"./material/degradation_operators/sr16.pt\"\n",
    "degradation_operator = torch.load(path_operator, map_location=\"cpu\")\n",
    "\n",
    "# apply degradation operator\n",
    "# NOTE: it operates on bach of images\n",
    "y = degradation_operator.H(x_origin[None])\n",
    "\n",
    "# reshape to plot the observation\n",
    "# NOTE: y is a square image with 3 channels\n",
    "n_channels = 3\n",
    "n_pixel_per_channel = y.shape[1] // n_channels\n",
    "hight = width = int(math.sqrt(n_pixel_per_channel))\n",
    "\n",
    "y_reshaped = y.reshape(n_channels, hight, width)\n",
    "\n",
    "# plot the image\n",
    "fig, ax = plt.subplots()\n",
    "display_image(y_reshaped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add Gaussian noise with $\\sigma = 0.1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add noise\n",
    "sigma = 0.1\n",
    "y_reshaped_noised = y_reshaped + sigma * torch.randn_like(y_reshaped)\n",
    "\n",
    "# plot the three images side by side\n",
    "fig, axes = plt.subplots(1, 3)\n",
    "\n",
    "images = (x_origin, y_reshaped, y_reshaped_noised)\n",
    "titles = (\"original\", \"degraded\", \"degraded + noise\")\n",
    "\n",
    "for ax, img, title in zip(axes, images,titles):\n",
    "    display_image(img, ax)\n",
    "    ax.set_title(title)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "In the end, the inverse problem can be defined using the tuple ``(y, degradation_operator, sigma)``\n",
    "\n",
    "**Note**:\n",
    "In practice, we don't have access to $x$ (in the code ``x_origin``) but only to $y$, $A$, and $\\sigma$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example on CelebaHQ dataset with DPS algorithm\n",
    "\n",
    "The model details and checkpoint can be found in [Hugging Face](https://huggingface.co/google/ddpm-celebahq-256)\n",
    "\n",
    "Here, the package ``Diffusers`` is used under the hood to load the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beforehand, let's load the model and perform unconditional sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from py_source.utils import load_epsilon_net\n",
    "from py_source.sampling.unconditional import unconditional_sampling\n",
    "\n",
    "\n",
    "# load the noise predictor with 1000 diffusion steps\n",
    "device = \"cuda:0\"\n",
    "n_steps = 1000\n",
    "torch.set_default_device(device)\n",
    "\n",
    "eps_net = load_epsilon_net(\"celebahq\", n_steps, device)\n",
    "\n",
    "# check unconditional generation\n",
    "# NOTE: use initial noise to specify number of generated samples\n",
    "initial_noise = torch.randn((1, 3, 256, 256), device=device)\n",
    "generated_images = unconditional_sampling(eps_net, initial_noise, display_im=False)\n",
    "\n",
    "# plot image\n",
    "fig, ax = plt.subplots()\n",
    "display_image(generated_images[0], ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all the building blocks to solve linear inverse problems.\n",
    "\n",
    "Let's solve SR16 problem with CelebaHQ model prior using DPS algorithm [1].\n",
    "\n",
    "\n",
    ".. [1] Chung, Hyungjin, et al. \"Diffusion posterior sampling for general noisy inverse problems.\" arXiv preprint arXiv:2209.14687 (2022).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\"\n",
    "torch.set_default_device(device)\n",
    "\n",
    "\n",
    "# define first the inverse problem\n",
    "\n",
    "# load the image\n",
    "img_path = \"./material/celebahq_img/00010.jpg\"\n",
    "x_origin = load_image(img_path, device)\n",
    "\n",
    "\n",
    "# load the degradation operator\n",
    "path_operator = f\"./material/degradation_operators/sr16.pt\"\n",
    "degradation_operator = torch.load(path_operator, map_location=device)\n",
    "\n",
    "# apply degradation operator\n",
    "y = degradation_operator.H(x_origin[None])\n",
    "y = y.squeeze(0)\n",
    "\n",
    "# add noise\n",
    "sigma = 0.01\n",
    "y = y + sigma * torch.randn_like(y)\n",
    "\n",
    "inverse_problem = (y, degradation_operator, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_source.utils import load_epsilon_net\n",
    "from py_source.sampling.dps import dps\n",
    "\n",
    "# load model with 500 diffusion steps\n",
    "n_steps = 500\n",
    "eps_net = load_epsilon_net(\"celebahq\", n_steps, device)\n",
    "\n",
    "# solve problem\n",
    "initial_noise = torch.randn((1, 3, 256, 256), device=device)\n",
    "reconstruction = dps(initial_noise, inverse_problem, eps_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot results\n",
    "\n",
    "# reshape y\n",
    "n_channels = 3\n",
    "n_pixel_per_channel = y.shape[0] // n_channels\n",
    "hight = width = int(math.sqrt(n_pixel_per_channel))\n",
    "\n",
    "y_reshaped = y.reshape(n_channels, hight, width)\n",
    "\n",
    "# init figure\n",
    "fig, axes = plt.subplots(1, 3)\n",
    "\n",
    "images = (x_origin, y_reshaped, reconstruction[0])\n",
    "titles = (\"original\", \"degraded\", \"reconstruction\")\n",
    "\n",
    "# display figures\n",
    "for ax, img, title in zip(axes, images,titles):\n",
    "    display_image(img, ax)\n",
    "    ax.set_title(title)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example on FFHQ dataset with $\\Pi\\text{GDM}$ algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model details can be found in [Diffusion Posterior Sampling for General Noisy Inverse Problems](https://arxiv.org/abs/2209.14687) in the Experiment section.\n",
    "\n",
    "The model checkpoint, ``ffhq_10m.pt``, can be downloaded [here](https://drive.google.com/drive/folders/1jElnRoFv7b31fG0v6pTSQkelbSX3xGZh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beforehand, let's load the model and perform unconditional sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load the noise predictor with 500 diffusion steps\n",
    "device = \"cuda:0\"\n",
    "n_steps = 1000\n",
    "torch.set_default_device(device)\n",
    "\n",
    "eps_net = load_epsilon_net(\"ffhq\", n_steps, device)\n",
    "\n",
    "# check unconditional generation\n",
    "# NOTE: use initial noise to specify number of generated samples\n",
    "initial_noise = torch.randn((1, 3, 256, 256), device=device)\n",
    "generated_images = unconditional_sampling(eps_net, initial_noise, display_im=False)\n",
    "\n",
    "# plot image\n",
    "fig, ax = plt.subplots()\n",
    "display_image(generated_images[0], ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's solve an inpainting problem with FFHQ prioir using $\\Pi\\text{GDM}$ algorithm [1]\n",
    "\n",
    ".. [1] Song, Jiaming, et al. \"Pseudoinverse-guided diffusion models for inverse problems.\" International Conference on Learning Representations. 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\"\n",
    "torch.set_default_device(device)\n",
    "\n",
    "\n",
    "# define first the inverse problem\n",
    "\n",
    "# load the image\n",
    "img_path = \"./material/ffhq_img/00018.png\"\n",
    "x_origin = load_image(img_path, device)\n",
    "\n",
    "# load the degradation operator\n",
    "path_operator = f\"./material/degradation_operators/inpainting_middle.pt\"\n",
    "degradation_operator = torch.load(path_operator, map_location=device)\n",
    "\n",
    "# apply degradation operator\n",
    "y = degradation_operator.H(x_origin[None])\n",
    "y = y.squeeze(0)\n",
    "\n",
    "# add noise\n",
    "sigma = 0.01\n",
    "y = y + sigma * torch.randn_like(y)\n",
    "\n",
    "inverse_problem = (y, degradation_operator, sigma)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This algorithm leverages the SVD decomposition of the degradation operator $A = U^\\top \\Sigma V$\n",
    "\n",
    "Therefore, let's use ``EpsilonNetSVD`` to make the right transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_source.utils import load_epsilon_net\n",
    "from py_source.sampling.pgdm import pgdm_svd\n",
    "from py_source.sampling.epsilon_net import EpsilonNetSVD\n",
    "\n",
    "# load model with 500 diffusion steps\n",
    "n_steps = 500\n",
    "eps_net = load_epsilon_net(\"ffhq\", n_steps, device)\n",
    "\n",
    "eps_net_svd = EpsilonNetSVD(\n",
    "        net=eps_net.net,\n",
    "        alphas_cumprod=eps_net.alphas_cumprod,\n",
    "        timesteps=eps_net.timesteps,\n",
    "        H_func=degradation_operator,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "# solve problem\n",
    "initial_noise = torch.randn((1, 3, 256, 256), device=device)\n",
    "reconstruction = pgdm_svd(initial_noise, inverse_problem, eps_net_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot results\n",
    "\n",
    "# reshape y\n",
    "y_reshaped =  -torch.ones(3 * 256 * 256, device=device)\n",
    "y_reshaped[: y.shape[0]] = y\n",
    "y_reshaped = degradation_operator.V(y_reshaped[None])\n",
    "y_reshaped = y_reshaped.reshape(3, 256, 256)\n",
    "\n",
    "\n",
    "# init figure\n",
    "fig, axes = plt.subplots(1, 3)\n",
    "\n",
    "images = (x_origin, y_reshaped, reconstruction[0])\n",
    "titles = (\"original\", \"degraded\", \"reconstruction\")\n",
    "\n",
    "# display figures\n",
    "for ax, img, title in zip(axes, images,titles):\n",
    "    display_image(img, ax)\n",
    "    ax.set_title(title)\n",
    "\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
